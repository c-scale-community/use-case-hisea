{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# notebook for troubleshooting and testing solutions for issues in the workflow\n",
    "\n",
    "Note this is a testing notebook. In this notebook we test different approaches used in our workflow. Mostly these were tested locally, so the paths to data etc will not work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tests to find solution for https://github.com/c-scale-community/use-case-hisea/issues/28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from datetime import timedelta, datetime\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "import xarray as xr # note dependencies: dask, netCdata4\n",
    "\n",
    "vars = ('thetao', 'bottomT', 'so', 'zos', 'uo', 'vo')\n",
    "date_min = '2022-04-01'\n",
    "date_max = '2022-04-05'\n",
    "\n",
    "delta = datetime.strptime(date_max, '%Y-%m-%d') - datetime.strptime(date_min, '%Y-%m-%d')\n",
    "\n",
    "var = vars[0]\n",
    "i = 0\n",
    "day = datetime.strptime(date_min, '%Y-%m-%d').date() + timedelta(days=i)\n",
    "check_file = Path('/Users/backeb/Documents/data/tmp/cmems_'+str(var)+'_'+str(day)+'.nc')\n",
    "\n",
    "j=0\n",
    "while not check_file.is_file():\n",
    "    print('j '+str(i))\n",
    "    print(check_file.is_file())\n",
    "    open(check_file, 'a')\n",
    "    j+=1\n",
    "\n",
    "print(check_file.is_file())\n",
    "print(j)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# alternate way to concat netcdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import xarray as xr\n",
    "\n",
    "datasets = []\n",
    "#for path in Path('/Users/backeb/Documents/data/tmp/').iterdir():\n",
    "for path in sorted(Path('/Users/backeb/Documents/data/tmp/').rglob('*no3*.nc')):\n",
    "    print(path)\n",
    "    ds = xr.open_dataset(path, decode_times=False)\n",
    "    datasets.append(ds)\n",
    "combined = xr.concat(datasets, dim='time')\n",
    "\n",
    "print(combined)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# for download_era5.py get an error when iterating over months\n",
    " e.g. from 2021-07-01 to 2022-06-31 the monthstr is empty \\\n",
    " this is because I'm trying to do `for i in range(7, 6, 1): ...` \\\n",
    " tests to find a better way to iterate over a period \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "\n",
    "date_min = '2021-07-01'\n",
    "date_max = '2022-06-30'\n",
    "\n",
    "yearstr = []\n",
    "pdyears = pd.period_range(start=date_min, end=date_max, freq='Y')\n",
    "[yearstr.append(f'{year:0>4}') for year in pdyears.year]\n",
    "print(yearstr)\n",
    "\n",
    "monthstr = []\n",
    "pdmonths = pd.period_range(start=date_min, end=date_max, freq='M')\n",
    "#print(np.unique(pdmonths.month))\n",
    "[monthstr.append(f'{month:0>2}') for month in np.unique(pdmonths.month)]\n",
    "print(monthstr)\n",
    "\n",
    "daystr = []\n",
    "pddays = pd.period_range(start=date_min, end=date_max, freq='D')\n",
    "#print(np.unique(pddays.day))\n",
    "[daystr.append(f'{day:0>2}') for day in np.unique(pddays.day)]\n",
    "print(daystr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tests to change download_era5.py to deal with CDS API limitation: https://github.com/c-scale-community/use-case-hisea/issues/30\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta, datetime\n",
    "\n",
    "date_min = '2021-07-01'\n",
    "date_max = '2022-06-30'\n",
    "vars = ('10m_u_component_of_wind', '10m_v_component_of_wind', 'mean_sea_level_pressure', '2m_dewpoint_temperature', 'relative_humidity', 'surface_net_solar_radiation', '2m_temperature', 'total_cloud_cover')\n",
    "\n",
    "vars = list(vars)\n",
    "print(vars)\n",
    "\n",
    "delta = datetime.strptime(date_max, '%Y-%m-%d') - datetime.strptime(date_min, '%Y-%m-%d')\n",
    "i = 0\n",
    "day = datetime.strptime(date_min, '%Y-%m-%d').date() + timedelta(days=i)\n",
    "yearstr = [f'{day.year:0>4}']\n",
    "print(yearstr)\n",
    "monthstr = [f'{day.month:0>2}']\n",
    "print(monthstr)\n",
    "daystr = [f'{day.day:0>2}']\n",
    "print(daystr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tests to figure out https://github.com/c-scale-community/use-case-hisea/issues/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta, datetime\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "import xarray as xr\n",
    "\n",
    "username = 'insert'\n",
    "password = 'insert'\n",
    "longitude_min = 22.5\n",
    "longitude_max = 24.5\n",
    "latitude_min = 36.5\n",
    "latitude_max = 38.5\n",
    "date_min = '2022-04-01'\n",
    "date_max = '2022-04-02'\n",
    "vars = ('thetao', 'bottomT', 'so', 'zos', 'uo', 'vo')\n",
    "\n",
    "#make the /data/tmp directory if it does not exist\n",
    "Path('/data/tmp').mkdir(parents=True, exist_ok=True)\n",
    "delta = datetime.strptime(date_max, '%Y-%m-%d') - datetime.strptime(date_min, '%Y-%m-%d')\n",
    "for var in vars:\n",
    "        for i in range(delta.days+1):\n",
    "                max_runs = 2\n",
    "                run = 0\n",
    "                day = datetime.strptime(date_min, '%Y-%m-%d').date() + timedelta(days=i)\n",
    "                check_file = Path('/data/tmp/cmems_'+str(var)+'_'+str(day)+'.nc')\n",
    "                while not check_file.is_file() and run < max_runs:\n",
    "                        try:\n",
    "                                subprocess.run(['python', '-m', 'motuclient',\n",
    "                                        '--motu', 'https://nrt.cmems-du.eu/motu-web/Motu',\n",
    "                                        '--service-id', 'GLOBAL_ANALYSIS_FORECAST_PHY_001_024-TDS',\n",
    "                                        '--product-id', 'global-analysis-forecast-phy-001-024',\n",
    "                                        '--longitude-min',str(longitude_min),\n",
    "                                        '--longitude-max', str(longitude_max),\n",
    "                                        '--latitude-min', str(latitude_min),\n",
    "                                        '--latitude-max', str(latitude_max),\n",
    "                                        '--date-min', str(day)+' 12:00:00',\n",
    "                                        '--date-max', str(day)+' 12:00:00',\n",
    "                                        '--depth-min', '0.493',\n",
    "                                        '--depth-max', '5727.918000000001',\n",
    "                                        '--variable', str(var),\n",
    "                                        '--out-dir', '/data/tmp',\n",
    "                                        '--out-name', 'cmems_'+str(var)+'_'+str(day)+'.nc',\n",
    "                                        '--user', username,\n",
    "                                        '--pwd', password],\n",
    "                                        check=True,\n",
    "                                        timeout=300)\n",
    "                        except subprocess.TimeoutExpired as e:\n",
    "                                print(var)\n",
    "                                print(e.stdout)\n",
    "                                print(e.stderr)\n",
    "                                continue\n",
    "                        else:\n",
    "                                break\n",
    "                        finally:\n",
    "                                run += 1\n",
    "        ds = xr.open_mfdataset('/data/tmp/cmems_'+var+'_*.nc')\n",
    "        ds.to_netcdata('/data/cmems_'+var+'.nc')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# temporary workaround to update RadSurf_daily.tim: https://github.com/c-scale-community/use-case-hisea/issues/43#issuecomment-1463896339\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pname = '../fm_model/input/'\n",
    "fname = 'RadSurf_daily.tim'\n",
    "\n",
    "data = pd.read_csv(pname+fname, delim_whitespace=True, header=None)#, names=[\"Time\", \"Value\"])\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the first 730 points\n",
    "plt.plot(data.iloc[:730, 0], data.iloc[:730, 1])\n",
    "\n",
    "# Overlay the next 730 points, and so on\n",
    "for i in range(730, len(data), 730):\n",
    "    plt.plot(data.iloc[i:i+730, 0], data.iloc[i:i+730, 1])\n",
    "    \n",
    "# Add labels and title\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Value')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the last 100 data points as different coloured dots\n",
    "plt.scatter(data.iloc[-730:, 0], data.iloc[-730:, 1])\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Value')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the reference time\n",
    "tref = pd.to_datetime('2015-01-01')\n",
    "\n",
    "# Add a datetime column based on the first column\n",
    "data['datetime'] = pd.to_datetime(tref) + pd.to_timedelta(data.iloc[:, 0], unit='m')\n",
    "\n",
    "# Print the updated dataframe\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# Filter out future warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# Your code here\n",
    "\n",
    "# Reset warning filters\n",
    "warnings.resetwarnings()\n",
    "\n",
    "# Append an empty row\n",
    "data = data.append({}, ignore_index=True)\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the previous value in column 0\n",
    "prev_value = data.iloc[-2, 0]\n",
    "\n",
    "# Get the unique difference between all the values in column 0\n",
    "unique_diff = data[0].diff().dropna().unique()\n",
    "print(unique_diff)\n",
    "\n",
    "# Fill the value in column 0, row 2920 with the previous value plus the unique difference\n",
    "data.iloc[-1, 0] = prev_value + unique_diff.sum()\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set datetime of last row to the corresponding value in column 0\n",
    "data.iloc[-1, 2] = pd.to_datetime('2015-01-01') + pd.to_timedelta(data.iloc[-1, 0], unit='m')\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the day and month of the datetime in the last row\n",
    "last_date = data.iloc[-1]['datetime']\n",
    "last_day_month = last_date.strftime('%m-%d')\n",
    "\n",
    "# Create a mask to filter the rows with the same day and month\n",
    "mask = data['datetime'].dt.strftime('%m-%d') == last_day_month\n",
    "\n",
    "# Compute the average of values in column 1 for these rows\n",
    "# Set the value in the last row of column 1 as the average\n",
    "data.iloc[-1, 1] = data.loc[mask, 1].mean()\n",
    "\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the last 100 data points as different coloured dots\n",
    "plt.scatter(data.iloc[-730:, 0], data.iloc[-730:, 1], c=range(730), cmap='viridis')\n",
    "\n",
    "# Plot the last value as a red dot\n",
    "plt.scatter(data.iloc[-1, 0], data.iloc[-1, 1], color='red')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Value')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0           0\n",
      "1           0\n",
      "datetime    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count the number of NaN values in each column\n",
    "nan_counts = data.isna().sum()\n",
    "\n",
    "# Print the results\n",
    "print(nan_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### final solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import pandas as pd\n",
    "pname = '../fm_model/input/'\n",
    "fname = 'RadSurf_daily.tim'\n",
    "\n",
    "data = pd.read_csv(pname+fname, delim_whitespace=True, header=None)#, names=[\"Time\", \"Value\"])\n",
    "\n",
    "# Define the reference time\n",
    "tref = pd.to_datetime('2015-01-01')\n",
    "#print(tref, '\\n')\n",
    "\n",
    "# Add a datetime column based on the first column\n",
    "data['datetime'] = pd.to_datetime(tref) + pd.to_timedelta(data.iloc[:, 0], unit='m')\n",
    "\n",
    "# get the number of days between the last datetime in the last row and date_max\n",
    "date_max = pd.to_datetime('2023-03-11')\n",
    "last_datetime = data.iloc[-1]['datetime']\n",
    "days_diff = int((date_max - last_datetime) / pd.Timedelta(days=1))\n",
    "#print(days_diff, '\\n')\n",
    "\n",
    "\n",
    "for i in range(days_diff+1):\n",
    "\n",
    "    # Append an empty row\n",
    "    data = data.append({}, ignore_index=True)\n",
    "\n",
    "    # Get the previous value in column 0\n",
    "    prev_value = data.iloc[-2, 0]\n",
    "    #print(prev_value, '\\n')\n",
    "\n",
    "    # Get the unique difference between all the values in column 0\n",
    "    unique_diff = data[0].diff().dropna().unique()\n",
    "    #print(unique_diff, '\\n')\n",
    "\n",
    "    # Fill the value in column 0, last row with the previous value plus the unique differenc\n",
    "    data.iloc[-1, 0] = prev_value + unique_diff\n",
    "\n",
    "    # Set datetime of last row to the corresponding value from column 0\n",
    "    data.iloc[-1, 2] = tref + pd.to_timedelta(data.iloc[-1, 0], unit='m')\n",
    "\n",
    "    # Get the day and month of the datetime in the last row\n",
    "    last_date = data.iloc[-1]['datetime']\n",
    "    last_day_month = last_date.strftime('%m-%d')\n",
    "    #print(last_date)\n",
    "    #print(last_day_month)\n",
    "\n",
    "    # Create a mask to filter the rows with the same day and month\n",
    "    mask = data['datetime'].dt.strftime('%m-%d') == last_day_month\n",
    "\n",
    "    # Compute the average of values in column 1 for these rows\n",
    "    # Set the value in the last row of column 1 as the average\n",
    "    data.iloc[-1, 1] = data.loc[mask, 1].mean()\n",
    "    \n",
    "\n",
    "# convert column 0 to integers\n",
    "data[0] = data[0].astype(int)\n",
    "\n",
    "# Round the values in column 1 to 11 decimal places\n",
    "data[1] = data[1].round(decimals=11)\n",
    "\n",
    "# write to file\n",
    "data.to_csv('output.txt', columns=[0,1], header=False, index=False, sep='\\t')\n",
    "\n",
    "#print(data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the last 730 data points \n",
    "plt.scatter(data.iloc[:, 0], data.iloc[:, 1])\n",
    "\n",
    "# Plot the last value as a red dot\n",
    "plt.scatter(data.iloc[-days_diff:, 0], data.iloc[-days_diff:, 1], color='red')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Value')\n",
    "plt.show()\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### click() comand line interface for final solution: https://github.com/c-scale-community/use-case-hisea/blob/main/scripts/workarounds/update_existing_RadSurf_daily_dot_tim.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: [backeb](https://github.com/backeb)\n",
    "# This code reads in a RadSurf_daily.tim file and extends the timeseries to a date specified by the user. \n",
    "# The new data is then written to an output file specified by the user.\n",
    "#\n",
    "# To use the script, the user needs to provide the following options as command-line arguments:\n",
    "#\n",
    "# --tref: Reference time as YYYY-MM-DD\n",
    "# --filename_in: Path/filename of input file\n",
    "# --filename_out: Path/filename of output file\n",
    "# --date_max: Date_max as YYYY-MM-DD\n",
    "#\n",
    "# Once the user provides the required options, they can run the script and it will\n",
    "#\n",
    "# 1. Read the data from the input file specified in --filename_in option.\n",
    "# 2. Add a datetime column based on the first column and reference time specified in --tref option.\n",
    "# 3. Determine the number of days between the last datetime in the last row and date_max specified in --date_max option.\n",
    "# 4. Append empty rows to the data to cover the missing days.\n",
    "# 5. Fill in the missing values in column 0 using previous value and unique differences.\n",
    "# 6. Fill in the missing datetime values using column 0 and reference time.\n",
    "# 7. Compute the average of values in column 1 for rows with the same day and month as the last row.\n",
    "# 8. Write the transformed data to a new file specified in --filename_out option with columns [0,1], separated by tabs and with floating point numbers in column 1 rounded to 8 decimal places.\n",
    "# The user can also add the --help option to see the help message and the list of available options.\n",
    "# \n",
    "# Below is an example of the scripts usage:\n",
    "#   `python update_existing_RadSurf_daily_dot_tim.py --tref '2015-01-01' --filename_in ../../fm_model/input/RadSurf_daily.tim --filename_out output.txt --date_max '2023-03-11'`\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import click\n",
    "import warnings\n",
    "\n",
    "# Ignore FutureWarning\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "@click.command()\n",
    "@click.option('--tref', type=str, help='Reference time as YYYY-MM-DD')\n",
    "@click.option('--filename_in', help='path/filename of input file')\n",
    "@click.option('--filename_out', help='path/filename of output file')\n",
    "@click.option('--date_max', help='date_max as YYYY-MM-DD')\n",
    "def main(tref, filename_in, filename_out, date_max):\n",
    "\n",
    "    # Define the reference time\n",
    "    tref = pd.to_datetime(tref)\n",
    "    #print(tref, '\\n')\n",
    "\n",
    "    # Read the data from file\n",
    "    data = pd.read_csv(filename_in, delim_whitespace=True, header=None)\n",
    "\n",
    "    # Add a datetime column based on the first column\n",
    "    data['datetime'] = tref + pd.to_timedelta(data.iloc[:, 0], unit='m')\n",
    "\n",
    "    # get the number of days between the last datetime in the last row and date_max\n",
    "    date_max = pd.to_datetime(date_max)\n",
    "    last_datetime = data.iloc[-1]['datetime']\n",
    "    days_diff = int((date_max - last_datetime) / pd.Timedelta(days=1))\n",
    "    #print(days_diff, '\\n')\n",
    "\n",
    "    for i in range(days_diff+1):\n",
    "\n",
    "        # Append an empty row\n",
    "        data = data.append({}, ignore_index=True)\n",
    "\n",
    "        # Get the previous value in column 0\n",
    "        prev_value = data.iloc[-2, 0]\n",
    "        #print(prev_value, '\\n')\n",
    "\n",
    "        # Get the unique difference between all the values in column 0\n",
    "        unique_diff = data[0].diff().dropna().unique()\n",
    "        #print(unique_diff, '\\n')\n",
    "\n",
    "        # Fill the value in column 0, last row with the previous value plus the unique differenc\n",
    "        data.iloc[-1, 0] = prev_value + unique_diff\n",
    "\n",
    "        # Set datetime of last row to the corresponding value from column 0\n",
    "        data.iloc[-1, 2] = tref + pd.to_timedelta(data.iloc[-1, 0], unit='m')\n",
    "\n",
    "        # Get the day and month of the datetime in the last row\n",
    "        last_date = data.iloc[-1]['datetime']\n",
    "        last_day_month = last_date.strftime('%m-%d')\n",
    "        #print(last_date)\n",
    "        #print(last_day_month)\n",
    "\n",
    "        # Create a mask to filter the rows with the same day and month\n",
    "        mask = data['datetime'].dt.strftime('%m-%d') == last_day_month\n",
    "\n",
    "        # Compute the average of values in column 1 for these rows\n",
    "        # Set the value in the last row of column 1 as the average\n",
    "        data.iloc[-1, 1] = data.loc[mask, 1].mean()\n",
    "\n",
    "    # convert column 0 to integers\n",
    "    data[0] = data[0].astype(int)\n",
    "\n",
    "    # write to file\n",
    "    data.to_csv(filename_out, columns=[0,1], header=False, index=False, sep='\\t', float_format='%.8f')\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "3d597f4c481aa0f25dceb95d2a0067e73c0966dcbd003d741d821a7208527ecf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
